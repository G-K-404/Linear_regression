<h1>ğŸ“ˆ Linear Regression from Scratch in Python</h1>
This project demonstrates a complete implementation of univariate linear regression using both Gradient Descent and Stochastic Gradient Descent (SGD). It includes data normalization, model training, evaluation using accuracy metrics like RÂ² and MSE, and visualization of predicted vs actual outputs.

<h2>ğŸ”§ Features</h2>
<h3>Linear regression using:</h3>

Batch Gradient Descent

Stochastic Gradient Descent (SGD)

<h3>Works on both:</h3>

Custom dummy data(with significant R^2 value)

Real dataset (Salary_dataset.csv)

Data normalization (mean-standard deviation scaling)

Visualization using Matplotlib

Performance evaluation via:

RÂ² Score (Coefficient of Determination)

Mean Squared Error (MSE)

<h2>ğŸ“‚ File Structure</h2>
```plaintext
project/
â”‚
â”œâ”€â”€ archive2/
â”‚   â””â”€â”€ Salary_dataset.csv   
â”‚
â”œâ”€â”€ linear_regression.py    
â”œâ”€â”€ README.md                

```
<h2>ğŸ“Š Dataset</h2>
```plaintext
Path: ./archive2/Salary_dataset.csv
Format: CSV with two columns:

YearsExperience (independent variable x)

Salary (dependent variable y)
```
<a href="https://www.kaggle.com/datasets/abhishek14398/salary-dataset-simple-linear-regression/data">Dataset</a>
<h3>ğŸš€ How It Works</h3>
<h4>ğŸ” Model Equation</h4>
The prediction function is:
```equation
Å· = w1 + w2 * x
Where:

w1 is the bias

w2 is the weight

x is the input feature
```
<h4>ğŸ” Cost Function</h4>
The loss is measured using the Mean Squared Error (MSE):
```
MSE = (1/N) * Î£(Å· - y)Â²
```
<h3>ğŸ§  Optimization Methods</h3>
<h4>âœ… Batch Gradient Descent</h4>
Updates parameters using the average gradient over the full dataset.

<h4>ğŸ”„ Stochastic Gradient Descent (SGD)</h4>
Updates weights for each data point one at a time â€” faster, more volatile convergence.

<h3>ğŸ“ˆ Visualization</h3>
Plots are created using Matplotlib to show:

Original data (scatter plot)

Predicted line (regression line)

ğŸ“Š Accuracy Metrics
RÂ² Score: Measures how well predictions match actual values.

RÂ² = 1 - (SSR/SST)

Mean Squared Error (MSE): Measures average squared difference between predicted and actual values.

<h2>âš™ï¸ Usage</h2>
<h3>1. Clone the Repository</h3>
```bash
git clone https://github.com/yourusername/linear-regression-scratch.git
cd linear-regression-scratch
```
<h3>2. Run the Notebook or Script</h3>
Ensure matplotlib and numpy are installed:
```bash
pip install matplotlib numpy
```
Then run using Jupyter Notebook or directly execute the Python script.

<h2>ğŸ§ª Example Results</h2>
<h3>Using dummy data:</h3>

```yaml
Input: x = [1,2,3,...,10]
Output: y = [5,7,9,...,23]

Gradient Descent:
RÂ² â‰ˆ 1.0
MSE â‰ˆ very low

SGD:
RÂ² â‰ˆ 0.999
MSE â‰ˆ slightly higher
Using real dataset (Salary_dataset.csv):
```
Scaled data (mean-std normalization)

RÂ² â‰ˆ high (close to 0.9+ depending on data quality)

<h2>ğŸ“Œ Notes</h2>
Normalize inputs for better convergence.

Learning rate and epoch count highly affect convergence.

SGD gives quicker but noisier convergence compared to batch gradient descent.

